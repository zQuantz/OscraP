from const import DIR, DATE, DTDATE, DATA, CONVERTER, NUMBERS, CONFIG

from datetime import datetime, timedelta
from calculations import calculate_iv
from bs4 import BeautifulSoup
import pandas as pd
import numpy as np
import itertools
import sys, os
import time

sys.path.append(f"{DIR}/../utils")
from gcp import send_gcp_metric
from request import request

###################################################################################################

ANALYSIS = "https://ca.finance.yahoo.com/quote/{ticker}/analysis?p={ticker}"
STATS = "https://finance.yahoo.com/quote/{ticker}/key-statistics?p={ticker}"
OPTIONS = "https://finance.yahoo.com/quote/{ticker}/options?p={ticker}"
OHLC = "https://finance.yahoo.com/quote/{ticker}/history"
SUMMARY = "https://finance.yahoo.com/quote/{ticker}/"
PARSER = "lxml"

NAMED_DATE_FMT = "%B %d, %Y"

OPTION_COLS = [
	"date_current",
	"ticker",
	"expiration_date",
	"days_to_expiry",
	"option_type",
	"strike_price",
	"bid_price",
	"option_price",
	"ask_price",
	"implied_volatility",
	"volume",
	"open_interest"
]

OHLC_COLS = [
	"date_current",
	"ticker",
	"open_price",
	"high_price",
	"low_price",
	"close_price",
	"adjclose_price",
	"volume",
	"dividend_yield",
]

###################################################################################################

class Ticker():

	def __init__(self, ticker, logger, batch_id, retries=None, fault_dict=None):

		self.ticker = ticker
		self.logger = logger
		self.batch_id = batch_id

		self.retries = retries
		self.fault_dict = fault_dict

		if not retries or retries["ohlc"] or retries['options']:
			try:
				self.div = self.get_dividends()
				self.logger.info(f"{ticker},{batch_id},Dividend,Success,")
			except Exception as e:
				self.logger.warning(f"{ticker},{batch_id},Dividend,Failure,{e}")
			self.sleep()

			try:
				self.get_ohlc()
				self.logger.info(f"{ticker},{batch_id},OHLC,Success,")
			except Exception as e:
				self.logger.warning(f"{ticker},{batch_id},OHLC,Failure,{e}")
				if e.args[0] == "Fatal":
					raise Exception("Stale ticker. Data not up-to-date.")
			self.sleep()

		if not retries or retries['keystats']:
			try:
				self.get_keystats()
				self.logger.info(f"{ticker},{batch_id},Key Stats,Success,")
			except Exception as e:
				self.logger.warning(f"{ticker},{batch_id},Key Stats,Failure,{e}")
			self.sleep()

		if not retries or retries['analysis']:
			try:
				self.get_analysis()
				self.logger.info(f"{ticker},{batch_id},Analysis,Success,")
			except Exception as e:
				self.logger.warning(f"{ticker},{batch_id},Analysis,Failure,{e}")
			self.sleep()

		if not retries or retries['options']:
			try:
				self.options = []
				self.get_options()
				self.logger.info(f"{ticker},{batch_id},Options,Success,")	
			except Exception as e:
				self.logger.warning(f"{ticker},{batch_id},Options,Failure,{e}")			
			self.sleep()

	def sleep(self):

		time.sleep(0.5)

	def fmt(self, str_, metric=''):

		try:
			date = datetime.strptime(str_, "%b %d, %Y")
			return date.strftime("%Y-%m-%d")
		except Exception as e:
			pass

		default_value = '' if 'Date' in metric else '' if 'Factor' in metric else 0

		if ':' in str_:
			return str_
		
		if str_ in ['', 'N/A', 'âˆž']:
			return None
		
		str_ = str_.replace(',', '').replace('$', '')

		modifier = str_[-1]
		if modifier in NUMBERS:
			return np.round(float(str_), 5)
		
		if modifier == '%':
			return np.round(float(str_[:-1]) / 100, 5)
		
		if modifier in ['M', 'B', 'T']:
			return np.round(float(str_[:-1]) * CONVERTER[modifier], 5)

	def option_fmt(self, str_number, metric=''):
	
		if str_number == '':
			return 0

		if str_number == 'N/A':
			return 0

		for token in ',$%':
			str_number = str_number.replace(token, '')

		return float(str_number.replace('-', '0'))

	def feature_conversion(self, str_):

		str_ = str_.split()
		if str_[-1] in NUMBERS:
			str_ = str_[:-1]
		str_ = ' '.join(str_)
		
		if '(' in str_:
			modifier = str_[str_.find('(')+1:str_.rfind(')')]
			feature_name = str_.split('(')[0]
			return (feature_name.strip(), modifier)
		else:
			return (str_, '')

	def drop_by_na(self, pkey, df, key='value'):

		def select_nna(x): 
			nn = x.value.notnull()
			if nn.sum() > 0:
				return x.loc[nn, key].values[0]
			else:
				return x[key].values[0]

		df = df.groupby(pkey).apply(lambda x: select_nna(x))
		return df.rename(key).reset_index(drop=False)

	def get_dividends(self):

		url = SUMMARY.format(ticker = self.ticker)
		bs = BeautifulSoup(request(CONFIG, url, self.logger).content, PARSER)

		table = bs.find_all("table")[1]
		div = table.find("td", {"data-test" : "DIVIDEND_AND_YIELD-value"})

		if not div:
			div = table.find("td", {"data-test" : "TD_YIELD-value"}).text
		else:
			div = div.text.split(' ')[1][1:-1]
			div = div.replace('N/A', '')

		return self.option_fmt(div, 'Dividend')

	def get_ohlc(self):

		url = OHLC.format(ticker = self.ticker)
		bs = BeautifulSoup(request(CONFIG, url, self.logger).content, PARSER)

		prices = bs.find("table", {"data-test" : "historical-prices"})
		prices = prices.find_all("tr")[1]
		prices = [price.text for price in prices]

		ohlc_date = datetime.strptime(prices[0], "%b %d, %Y").strftime("%Y-%m-%d")
		if ohlc_date != DATE:
			raise Exception(f'Fatal')

		prices = list(map(self.option_fmt, prices[1:], OHLC_COLS[:-2]))
		prices = [DATE, self.ticker] + prices + [self.div]
		self.adj_close = prices[-3]

		ohlc = pd.DataFrame([prices], columns = OHLC_COLS)
		ohlc.to_csv(f"{DATA}/ohlc/{self.ticker}_{DATE}.csv", index=False)

		if self.retries and self.retries['ohlc']:

			self.fault_dict['ohlc']['new_status'] = 1
			self.logger.info(f"{self.ticker},{self.batch_id},Re-OHLC,Success,1")

	def get_options(self):

		def get_page(url):

			ctr, max_ctr = 0, 3
			while (ctr < max_ctr):	
				
				bs = BeautifulSoup(request(CONFIG, url, self.logger).content, PARSER)
				options = bs.find_all("option")

				if len(options) != 0:
					break

				ctr += 1
				self.logger.info(f"{self.ticker},{self.batch_id},Option Download,{ctr}")
				self.sleep()

			return bs, options

		def append_options(table, expiry_date_fmt, expiration_days, option_type):

			for row in table.find_all("tr")[1:]:
				es = [e for e in row.find_all("td")[2:]]
				self.options.append([
						DATE,
						self.ticker,
						expiry_date_fmt,
						expiration_days,
						option_type,
						self.option_fmt(es[0].text, 'Strike Price'),
						self.option_fmt(es[2].text, 'Bid'),
						self.option_fmt(es[1].text, 'Option Price'),
						self.option_fmt(es[3].text, 'Ask'),
						self.option_fmt(es[-1].text, 'Implied Volatility'),
						self.option_fmt(es[-2].text, 'Volume'),
						self.option_fmt(es[-3].text, 'Open Interest')
					])

		url = OPTIONS.format(ticker = self.ticker)
		bs, options = get_page(url)

		for option in options:

			self.sleep()

			expiry, expiry_date = option.get("value"), option.text
			self.logger.info(f"{self.ticker},{self.batch_id},Option Expiry,{expiry},{expiry_date.replace(',', '.')}")

			expiry_date = datetime.strptime(expiry_date, NAMED_DATE_FMT)
			expiry_date_fmt = expiry_date.strftime("%Y-%m-%d")
			
			tdays = CONFIG['trading_days']
			try:
				expiration_days = tdays.index(expiry_date_fmt) - tdays.index(DATE)
			except Exception as e:
				self.logger.warning(f"{self.ticker},{self.batch_id},Trading Days Fault,{e}")
				for i in range(1, 3):
					expd = (expiry_date - timedelta(days=i)).strftime("%Y-%m-%d")
					if expd in tdays:
						expiration_days = tdays.index(expd) - tdays.index(DATE)
						warning = f"{self.ticker},{self.batch_id},Not a Trading Day,{expiry},{expiration_days}"
						self.logger.warning(warning)
						break

			page = url+f"&date={str(expiry)}"
			bs, _ = get_page(page)

			calls = bs.find("table", {"class" : "calls"})
			puts = bs.find("table", {"class" : "puts"})
			
			if calls:
				append_options(calls, expiry_date_fmt, expiration_days, 'C')
			
			if puts:
				append_options(puts, expiry_date_fmt, expiration_days, 'P')

		df = pd.DataFrame(self.options, columns = OPTION_COLS)
		oid = df.ticker + ' ' + df.expiration_date + ' ' + df.option_type
		sp = df.strike_price.round(2).astype(str)
		sp = sp.str.rstrip("0").str.rstrip(".")
		df['option_id'] = oid + sp

		try:

			df['stock_price'] = self.adj_close
			df['dividend_yield'] = self.div
			df = df.merge(CONFIG['ratemap'], on="days_to_expiry", how="inner")
			df = calculate_iv(df)
			df = df.drop(["stock_price", "dividend_yield", "rate"], axis=1)

		except Exception as e:

			self.logger.warning(f"{self.ticker},{self.batch_id},Calculate IV,Failure,{e}")
			df['zimplied_volatility'] = 0

		zba = df[(df.bid_price == 0) | (df.ask_price == 0)].shape[0]
		# send_gcp_metric(CONFIG, "zero_bid_ask", "double_value", zba / (1 + len(df)))

		if not self.retries and len(df) > 0:
			
			df.to_csv(f"{DATA}/options/{self.ticker}_{DATE}.csv", index=False)

		elif len(df) != 0:
			
			try:
				old = pd.read_csv(f"{DATA}/options/{self.ticker}_{DATE}.csv")
			except Exception as e:
				old = pd.DataFrame()

			df = pd.concat([old, df]).reset_index(drop=True)
			df = df.drop_duplicates(subset=['expiration_date', 'strike_price', 'option_type'], keep="last")
			df = df.sort_values(['expiration_date', 'option_type', 'strike_price'])
			df.to_csv(f"{DATA}/options/{self.ticker}_{DATE}.csv", index=False)

			self.fault_dict['options']['new'] = len(df)
			delta = self.fault_dict['options']['new'] - self.fault_dict['options']['old']

			self.fault_dict['options']['delta'] = delta
			self.logger.info(f"{self.ticker},{self.batch_id},Re-Options,Success,{delta}")

		else:

			self.logger.info(f"{self.ticker},{self.batch_id},Options,None Collected,")

	def get_keystats(self):

		def get_items(bs, text):

			span = bs.find("span", text=text)
			main_div = span.parent.parent

			items = []
			for tr in main_div.find_all("tr"):
				
				tds = tr.find_all("td")
				if len(tds) == 0:
					continue

				items.append([tds[0].text, tds[1].text])

			return items

		url = STATS.format(ticker = self.ticker)
		bs = request(CONFIG, url, self.logger).content
		bs = BeautifulSoup(bs, PARSER)

		items = get_items(bs, "Financial Highlights")
		items.extend(get_items(bs, "Trading Information"))
		items.extend(get_items(bs, "Valuation Measures"))

		keystats = []
		for feature_name, feature in items:
			key = self.feature_conversion(feature_name)
			keystats.append([
				*key,
				self.fmt(feature, metric = key[0])
			])

		df = pd.DataFrame(keystats, columns = ["feature", "modifier", "value"])
		df = df.dropna(subset=["value"])

		pkey = ["feature", "modifier"]
		df.loc[:, pkey] = df[pkey].fillna('')

		df['ticker'] = self.ticker
		df['date_current'] = DATE

		if not self.retries and len(df) > 0:
			
			df.to_csv(f"{DATA}/keystats/{self.ticker}_{DATE}.csv", index=False)

		elif len(df) != 0:
			
			try:
				old = pd.read_csv(f"{DATA}/keystats/{self.ticker}_{DATE}.csv")
			except Exception as e:
				old = pd.DataFrame()

			df = pd.concat([old, df]).reset_index(drop=True)
			df = self.drop_by_na(pkey, df)
			df.to_csv(f"{DATA}/keystats/{self.ticker}_{DATE}.csv", index=False)

			self.fault_dict['keystats']['new'] = len(df)
			delta = self.fault_dict['keystats']['new'] - self.fault_dict['keystats']['old']
			
			self.fault_dict['keystats']['delta'] = delta
			self.logger.info(f"{self.ticker},{self.batch_id},Re-Key Stats,Success,{delta}")

		else:

			self.logger.info(f"{self.ticker},{self.batch_id},Key Stats,None Collected,")

	def get_analysis(self):

		def parse_table(table):

			trs = table.find_all("tr")
			header, rows = trs[0], trs[1:]

			header = header.find_all("th")
			table_name = header[0].text

			column_names = [name.text for name in header[1:]]

			data, row_names = [], []
			for row in rows:

				row = row.find_all("td")
				row_names.append(row[0].text)
				data.extend([ele.text for ele in row[1:]])	
				
			df = pd.DataFrame(list(itertools.product(*[row_names, column_names])))
			df.columns = ['feature', 'feature_two']

			df['category'] = table_name
			df['feature_two'], df['modifier'] = list(zip(*df.feature_two.apply(self.feature_conversion)))

			metrics = (df.category + ' ' + df.feature).values.tolist()
			df['value'] = [self.fmt(value, metric=metric) for value, metric in zip(data, metrics)]

			return df[['category', 'feature', 'feature_two', 'modifier', 'value']]

		url = ANALYSIS.format(ticker = self.ticker)
		bs = request(CONFIG, url, self.logger).content
		bs = BeautifulSoup(bs, PARSER)

		dfs = []
		tables = bs.find_all("table")
		for table in tables:
			dfs.append(parse_table(table))
		
		df = pd.concat(dfs)
		df = df.dropna(subset=["value"])
		
		pkey = ["category", "feature", "feature_two", "modifier"]
		df.loc[:, pkey] = df[pkey].fillna('')

		df['ticker'] = self.ticker
		df['date_current'] = DATE

		if not self.retries and len(df) > 0:
			
			df.to_csv(f"{DATA}/analysis/{self.ticker}_{DATE}.csv", index=False)

		elif len(df) != 0:

			try:
				old = pd.read_csv(f"{DATA}/analysis/{self.ticker}_{DATE}.csv")
			except Exception as e:
				old = pd.DataFrame()

			df = pd.concat([old, df]).reset_index(drop=True)
			df = self.drop_by_na(pkey, df)

			df.to_csv(f"{DATA}/analysis/{self.ticker}_{DATE}.csv", index=False)

			self.fault_dict['analysis']['new'] = len(df)
			delta = self.fault_dict['analysis']['new'] - self.fault_dict['analysis']['old']
			
			self.fault_dict['analysis']['delta'] = delta
			self.logger.info(f"{self.ticker},{self.batch_id},Re-Analysis,Success,{delta}")

		else:

			self.logger.info(f"{self.ticker},{self.batch_id},Analysis,None Collected,")
